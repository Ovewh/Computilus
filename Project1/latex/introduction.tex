\section*{Introduction}
There is no denying the influence the computing has had on science. Where we
today are at a point where the computer has become almost unanimous with the
scientist. In a time where the computer can solve all your problems, one might
ask if the old fashioned pen and paper method still necessary? We will argue for
the necessity old pen and paper thinking, and demonstrate how pen and paper and
computing supplement each other. 

For our demonstration we will look at a how to solve a second order
differential equation, specifically the general one dimensional Poisson's
equation \cref{eq:1}. We will show how not thinking about the problem at hand
and just computationally brute force  the solution can lead to huge performance
penalties.   
\begin{equation}\label{eq:2}
  f(x)= - \pd[^2u]{x^2}
\end{equation}

\subsection*{Numerical differentiation}
\par A computer can only operate in discrete steps, which means that variables
are stored as discrete variables. A discrete variable  defined over a particular
range, would 
have a step length $h$ between each value and can not represent any values in
between. This means that how well a discrete variable would approximate the
continuous variable depends on the size of the step length. The step length $h$
can either be set manually or it can be determined from the start and end
point of our range, $h = \frac{x_n -x_0}{n}$. Where $n$ is the number
of points we choose to have in our range. 
\par
The simplest way to compute the derivate numerically is to use what is called
forward difference method eq.(\ref{eq:1}) or equivalently backward difference
method (eq.\ref{eq:5}). If we include the limit $\lim_{h\to 0}$ we obtain the
classic definition of the derivate. 
\begin{equation}\label{eq:1}
    f'(x) \approx \frac{f(x+h)-f(x)}{h}
\end{equation}

\begin{equation}\label{eq:5}
  f'(x) \approx \frac{f(x-h)+f(x)}{h}
\end{equation}
Since numerical differentiation always will give an approximation of the
derivate, we would like to quantify our error. The error can be derived 
if we do a taylor series expansion of the $f(x+h)$ term in around $x$.
\begin{equation}\label{eq:4}
    f(x+h) = f(x) + h'f(x) + \frac{h^2f''(x)}{2} + \frac{h^3f'''(x)}{6} + \dots    
\end{equation}   
If we next insert this taylor expansion into eq.(\ref{eq:4}) we get:
\begin{equation}
  f'(x) = f'(x) + \frac{h f''(x)}{2} + \frac{h^2f'''(x)}{6} + \dots
\end{equation} 
Our approximation of the derivate includes $f'(x)$ and some terms which are
proportional to $h, h^2, h^3 \dots $ and since $h$ is assumed to be small the
$h$ terms would dominate. The error is said to be of the order $h$. 
\par
To get a numerical scheme for the second derivate we would just take the
derivate of \cref{eq:1} except for a slight modification. Instead of looking at $f''(x) \approx \frac{f'(x+h)-f'(x)}{h}$ we would use 
$f''(x) \approx\frac{f'(x)-f'(x-h)}{h}$. it is simple to prove that the two
expression are equivalent \cite{mathexh}. 
\begin{equation}
  f''(x) \approx \frac{f(x + h) - f(x) -f(x-h+h) +f(x-h)}{h^2}
\end{equation}
Then after a bit of a clean up we get an approximation for the second order
derivate (\cref{eq:secondorder}). 
\begin{equation}\label{eq:secondorder}
  f''(x) \approx \frac{f(x+h)-2f(x) + f(x-h)}{h^2}
\end{equation}
Then to quantify the error we proceed as for the first order derivate, by
expanding $f(x+h)$ and $f(x-h)$. 
\begin{equation}\label{eq:taylor_f_x-h}
  f(x-h) = f(x)- h f'(x) + \frac{h^2 f''(x)}{2} - \frac{h^3f'''(x)}{6} \dots 
\end{equation} 
Next we substitute the two taylor expansion \cref{eq:taylor_f_x-h} and 
\cref{eq:4} into the expression for second order derivate \cref{eq:secondorder}.
\begin{equation}
  f''(x) \approx f''(x) + \frac{h^2f^{(4)}(x)}{4!} + \frac{h^4 f^{(6)}(x)}{6!} + \dots
\end{equation}
Then we see that leading error term is for the second derivate is 
$\mathcal{O}(h^2)$.   
