\section{Methods}


Considering the one dimensional wave function
\begin{equation}
\gamma \frac{d^2 u(x)}{dx^2} = -F u(x)
\end{equation}
, with u(x) being the vertical displacement of a beam in the y direction.
x $\in [0, L]$, with L being the length of the beam. $\gamma$ is a material constant,
and F is a force towards the origin being applied at the right hand side of the beam.
We will use the boundary conditions u(0) = u(L) = 0, meaning the beam doesn't move
at the end points.


Since we want to solve this equation numerically we scale it.

Introducing $ \rho = \frac{x}{L} $ limits $\rho$ to $[0, 1]$ and scales the
equation to
$$\frac{d^2 u(\rho)}{d\rho^2} = - \frac{FL^2}{\gamma} u(\rho) = -\lambda u(\rho).$$

We discretize $\rho$ on a grid with N points, which
define the step length as $h = \frac{\rho_N - \rho_0}{N}$ with $\rho_N = 1$ and
$\rho_0 = 0$.

Using the three point formula for the second derivative $ u'' = \frac{u(\rho + h) - 2u(\rho) +
u(\rho -u))}{h^2} + O(h^2)$, the initial equation can be discretized as
$\frac{-u_{i+1} + 2u_i - u_{i-1}}{h^2} = \lambda u_i$
or, in matrix form
$ A \vec{u} = \lambda \vec{u}$
with A being a tridiagonal matrix with $a = \frac{-1}{h^2}$ on the upper and lower
diagonal, and $d = \frac{2}{h^2}$ on the diagonal. $\vec{u}^T = [u_1, u_2, ..., u_{n-1}]$

Our equation is now in the form of an eigenvalue problem, which has analytical
eigenvalues $\lambda_j = d + 2a\cos{(\frac{j\pi}{n+1})}$ for $j \in [1,2,...,n]$
where n is the size of A.

\subsection{Properties of orthogonal transformations}

An orthogonal transformation U has the property $U^T U = U U^T = I$.

Assuming we have an orthonormal basis consisting of $\vec{v}_i^T = [v_{1i},
v_{2i}, ... , v_{ni}]$ we know that $\vec{v}_i^T \vec{v}_j = \vec{v}_i \cdot
\vec{v}_j = \delta_{ij}$. Let $\vec{w}_i = U\vec{v}_i$. $\vec{w}_i^T \vec{w}_j =
(U\vec{v}_i)^T(U\vec{v}_j) = \vec{v}_i^T U^T U \vec{v}_j = \vec{v}_i^T \vec{v}_j
= \delta_{ij}$. This shows that a orthogonal transformation preserves the dot
product and orthogonality.

\subsection{Jacobi´s method}

The idea behind Jacobi´s method is to diagonalize A by applying an orthogonal
rotation R$^T$ a repeated number of times. By chosing a spesific angle $\theta$
we can zero out one element of the transformed matrix.
We will use the shorthand c = $\cos{\theta}$ and s = $\sin{\theta}$ where $\theta$
is the angle of rotation.


$$R(k,l,\theta) =
\begin{bmatrix}
  1       & \cdots  & 0       & \cdots  & 0       & \cdots  & 0 \\
  \vdots  & \ddots  &  \vdots &         & \vdots  &         & \vdots \\
  0       & \cdots  & c       & \cdots  & -s      & \cdots  & 0 \\
  \vdots  &         & \vdots  & \ddots  & \vdots  &         & \vdots\\
  0       & \cdots  & s       & \cdots  & c       & \cdots  & 0\\
  \vdots  &         & \vdots  &         &  \vdots & \ddots  & \vdots\\
  0       & \cdots  & 0       & \cdots  & 0       & \cdots  & 1
\end{bmatrix}
$$
where k and l is the row number containing c and -s, and s and c respectively.


After one transformation $R^T A R R^T \vec{x} = B (R^T \vec{x}) = \lambda (R^T
\vec{x})$ we see that the new eigenvector is $R^T\vec{x}$.

Performing the transformation results in the following matrix.
(refer compendium 216)

\begin{align}
  b_{ii} &= a_{ii}, i \neq k, i \neq \\
  b_{ik} &= a_{ik}c - a_{il}s, i \neq k, i \neq \\
  b_{il} &= a_{il}c + a_{ik}s, i \neq k, i \neq \\
  b_{kk} &= a_{kk}c^2 - 2a_{kl}cs + a_{ll}s^2 \\
  b_{ll} &= a_{ll}c^2 + 2a_{kl}cs + a_{kk}s^2 \\
  b_{kl} &= (a_{kk}- a_{ll})cs + a_{kl}(c^2 - s^2)
\end{align}

Since A is symmetric, the orthogonal transformation of A will also be symmetric
and we get

\begin{align}
  b_{ki} &= b_{ik} \\
  b_{li} &= b_{il} \\
  b_{lk} &= b_{lk}
\end{align}

From this we see that the only changes between B and A will be in the columns
and rows k,l.

$b_{kl} = (a_{kk}-a_{ll})cs + a_{kl} (c^2 + s^2) = 0$.
